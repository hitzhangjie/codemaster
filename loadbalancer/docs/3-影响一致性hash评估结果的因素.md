# 影响一致性hash评估结果的因素

我们主要关注负载均衡算法的 ”一致性“、”均匀性“ 这两点，我们的测试也围绕着这两点展开。为了使得测试更有价值，更有可信度，需要说明下接下来的测试方案。

**影响各负载均衡算法测试结果的，可能有以下几点：**

1. 服务物理节点数，固定为10

   - 涉及到一致性hash算法及其变体时，我们会分别对比虚节点数为5、10、20、50、100、1000时的数量（直观理解，虚节点越多越均匀，内存开销可能越大）
   - jump一致性hash，虚节点数量对内存没影响，但是该算法使用场景受限于节点只add不减少的场景（如只增加shards的存储场景）
   - rendezvous hash，非一致性hash，没有虚节点概念，但是时间复杂度从一致性hash的O(logn)下降到O(n)，当节点数很多时开销不可忽视

2. 待测试的playerid数量足够多（将playerid mapping到物理节点上去处理），要远多于节点数，比如100w

3. 待测试的playerid生成算法是否均匀，go标准库rand.Int()默认的source是均匀的，我们用这个方法来生成playerid

4. 各基于hash的负载均衡算法采用的hash函数是否一致，在从key计算hash value时，不一致的hash函数可能会导致分布不均匀，这样会导致难以评估各类负载均衡算法本身的差异性
    可以把常见实现的代码clone下来，统一调节下hash函数来验证下，控制变量下。

5. 一致性hash算法中，虚节点对应的hash value的计算，为了平衡负载均匀和开销，通常虚节点数量n可调整，这种情况下就没法按照经典一致性hash算法中那样提供n个hash函数了
    一般是对物理节点host做下处理，比如加前缀1、2、3或者后缀9、10、11后表示虚节点，然后再用同一个hash函数做计算。
这种做法是否能让各个虚节点在ring上分布均匀呢？这个跟hash函数有关，但是直观感受是不见得能均匀。

6. 用户playerid在采用与hash(host)时相同的hash函数，playerid的值域与其hash值，是否能在hash环上均匀分布呢？直观感受是，不见得。

上述这些都是影响我们评估算法质量的影响因素，在进行测试对比时要多关注。

**另外，关于“一致性”方面，通过算法本身的理论描述是可以给出一个理论值的：**

- 一致性hash，假设k个key，n个nodes，那么节点加入、离开后，需要remapping的key大约为k/n（均衡的前提下）
- 一致性hash with bounded load，这个虽然负载比较均衡，但是直观感受是“一致性”不如经典的“一致性hash”，因为它会在负载偏高时选择下一个节点
- jump consistent hash，这个算法只考虑存储场景data shards增加的情况，我们可以先延迟测试这个
- rendezvous hash，理论上来说，只要新加入的节点host不会导致hash(playerid, host)最大，就对原来的playerid没影响，但是有多少playerid会受影响呢？待理解

但是实际使用时到底怎么样，就跟key本身以及hash函数选择的优劣很有关系了。